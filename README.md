# Alexnet_Minst（深度学习和python作业）
基于Pytorch手写复现AlexNet识别Minst数据集

输入层：AlexNet首先使用大小为 224 × 224 × 3 图像作为输入，后改为227 × 227 × 3

第一层（卷积层）：包含96个大小为11×11的滤波器（其实是11×11×3），卷积步长为4，因此第一层输出大小为55×55×96；使用Relu激活函数输出；再经过LRN输出（后面被BN替代）；然构建一个核大小为3×3、步长为2的最大池化层进行数据降采样，进而输出大小为27×27×96

第二层（卷积层）：包含256个大小为5×5滤波器，卷积步长为1，同时利用padding保证输出尺寸不变，因此该层输出大小为27×27×256；使用Relu激活函数输出；再经过LRN输出（后面被BN替代）；然后再次通过核大小为3×3、步长为2的最大池化层进行数据降采样，进而输出大小为13×13×256

从第二层卷积开始，原始论文沿着通道数一分为二，分成2 个55x55x48 的张量，后续对 2 个张量进行卷积我们后续按照实际中更常用的方式计算卷积结果。（还是由于算力不够的原因）

第三层与第四层（卷积层）：均为卷积核大小为3×3、步长为1的same卷积padding为1，如下面的计算公式），共包含384个卷积核，卷积后使用Relu激活函数输出；因此两层的输出大小为13×13×384

第五层（卷积层）：同样为卷积核大小为3×3、步长为1的same卷积，但包含256个卷积核，进而输出大小为13×13×256；在数据进入全连接层之前再次通过一个核大小为3×3、步长为2的最大池化层进行数据降采样，数据大小降为6×6×256，并将数据扁平化处理展开为9216个单元。

第六层、第七层和第八层（全连接层）：全连接加上Softmax分类器输出1000类的分类结果，将近6千万个参数。
